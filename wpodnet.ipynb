{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "# run get-networks.sh to get the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the keras model and load the weights\n",
    "with open(\"data/lp-detector/wpod-net_update1.json\", 'r') as json_file:\n",
    "            model_json = json_file.read()\n",
    "wpod = model_from_json(model_json,custom_objects={})\n",
    "wpod.load_weights('data/lp-detector/wpod-net_update1.h5')\n",
    "weights=wpod.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the keras model architecture. \n",
    "# This architecture is slightly different from what the paper details. I implemented this one, instead of paper\n",
    "wpod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(weights[143])\n",
    "#wpod.get_layer(\"batch_normalization_24\").weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the same model in pytorch\n",
    "# Defined model using sequential, so any parallel components are done separately\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms, utils, models\n",
    "from torch import nn\n",
    "import torch\n",
    "from src.label import Label\n",
    "from src.utils import getWH, nms\n",
    "from src.projection_utils import getRectPts, find_T_matrix\n",
    "\n",
    "# Class to represent the residual blocks since they are somewhat parallel\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.module(inputs) + inputs\n",
    "\n",
    "#Class to represent detection block since it is parallel\n",
    "class Detection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define network layers\n",
    "        self.conv2 = nn.Conv2d(128,2,3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128,6,3, padding=1)\n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x1 = self.sm(self.conv2(inputs))\n",
    "        x2 = self.conv6(inputs)\n",
    "        return torch.cat([x1,x2],dim=1)   \n",
    "    \n",
    "# Define model architecture\n",
    "model = model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, 3, padding=1),\n",
    "    nn.BatchNorm2d(16,eps=0.001, momentum=0.99),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, 3, padding=1),\n",
    "    nn.BatchNorm2d(16,eps=0.001, momentum=0.99),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Conv2d(16, 32, 3, padding=1),\n",
    "    nn.BatchNorm2d(32,eps=0.001, momentum=0.99),\n",
    "    nn.ReLU(),    \n",
    "    # ----------------------------------------------------|\n",
    "    ResBlock(                                            #|\n",
    "        nn.Sequential(                                   #| \n",
    "            nn.Conv2d(32, 32, 3, padding=1),             #| \n",
    "            nn.BatchNorm2d(32,eps=0.001, momentum=0.99), #|\n",
    "            nn.ReLU(),                                   #|\n",
    "            nn.Conv2d(32, 32, 3, padding=1),             #| \n",
    "            nn.BatchNorm2d(32,eps=0.001, momentum=0.99), #|\n",
    "        )                                                #| \n",
    "    ),                                                   #|\n",
    "    nn.ReLU(),                                           #| \n",
    "    # ----------------------------------------------------|\n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Conv2d(32, 64, 3, padding=1),\n",
    "    nn.BatchNorm2d(64,eps=0.001, momentum=0.99),\n",
    "    nn.ReLU(),\n",
    "    # ----------------------------------------------------|\n",
    "    ResBlock(                                            #|\n",
    "        nn.Sequential(                                   #| \n",
    "            nn.Conv2d(64, 64, 3, padding=1),             #| \n",
    "            nn.BatchNorm2d(64,eps=0.001, momentum=0.99), #|\n",
    "            nn.ReLU(),                                   #|\n",
    "            nn.Conv2d(64, 64, 3, padding=1),             #|\n",
    "            nn.BatchNorm2d(64,eps=0.001, momentum=0.99), #|\n",
    "        )                                                #| \n",
    "    ),                                                   #|\n",
    "    nn.ReLU(),                                           #| \n",
    "    # ----------------------------------------------------| \n",
    "    \n",
    "    # ----------------------------------------------------|\n",
    "    ResBlock(                                            #|\n",
    "        nn.Sequential(                                   #| \n",
    "            nn.Conv2d(64, 64, 3, padding=1),             #| \n",
    "            nn.BatchNorm2d(64,eps=0.001, momentum=0.99), #|\n",
    "            nn.ReLU(),                                   #|\n",
    "            nn.Conv2d(64, 64, 3, padding=1),             #| \n",
    "            nn.BatchNorm2d(64,eps=0.001, momentum=0.99), #|\n",
    "        )                                                #| \n",
    "    ),                                                   #|\n",
    "    nn.ReLU(),                                           #| \n",
    "    # ----------------------------------------------------| \n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Conv2d(64, 64, 3, padding=1),                        #In code not paper \n",
    "    nn.BatchNorm2d(64,eps=0.001, momentum=0.99),\n",
    "    nn.ReLU(),                                              #In code not paper\n",
    "    # ----------------------------------------------------|\n",
    "    ResBlock(                                            #|\n",
    "        nn.Sequential(                                   #| \n",
    "            nn.Conv2d(64, 64, 3, padding=1),             #| \n",
    "            nn.BatchNorm2d(64,eps=0.001, momentum=0.99), #|\n",
    "            nn.ReLU(),                                   #|\n",
    "            nn.Conv2d(64, 64, 3, padding=1),             #| \n",
    "            nn.BatchNorm2d(64,eps=0.001, momentum=0.99), #|\n",
    "        )                                                #| \n",
    "    ),                                                   #|\n",
    "    nn.ReLU(),                                           #| \n",
    "    # ----------------------------------------------------|\n",
    "    \n",
    "    # ----------------------------------------------------|\n",
    "    ResBlock(                                            #|\n",
    "        nn.Sequential(                                   #| \n",
    "            nn.Conv2d(64, 64, 3, padding=1),             #| \n",
    "            nn.BatchNorm2d(64,eps=0.001, momentum=0.99), #|\n",
    "            nn.ReLU(),                                   #|\n",
    "            nn.Conv2d(64, 64, 3, padding=1),             #| \n",
    "            nn.BatchNorm2d(64,eps=0.001, momentum=0.99), #|\n",
    "        )                                                #| \n",
    "    ),                                                   #|\n",
    "    nn.ReLU(),                                           #| \n",
    "    # ----------------------------------------------------| \n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Conv2d(64, 128, 3, padding=1),\n",
    "    nn.BatchNorm2d(128,eps=0.001, momentum=0.99),\n",
    "    nn.ReLU(),                                              #In code not paper\n",
    "    # ----------------------------------------------------|\n",
    "    ResBlock(                                            #|\n",
    "        nn.Sequential(                                   #| \n",
    "            nn.Conv2d(128, 128, 3, padding=1),           #|\n",
    "            nn.BatchNorm2d(128,eps=0.001, momentum=0.99),#|\n",
    "            nn.ReLU(),                                   #|\n",
    "            nn.Conv2d(128, 128, 3, padding=1),           #|\n",
    "            nn.BatchNorm2d(128,eps=0.001, momentum=0.99),#|\n",
    "        )                                                #| \n",
    "    ),                                                   #|\n",
    "    nn.ReLU(),                                           #| \n",
    "    # ----------------------------------------------------|\n",
    "    \n",
    "    # ----------------------------------------------------|\n",
    "    ResBlock(                                            #|\n",
    "        nn.Sequential(                                   #| \n",
    "            nn.Conv2d(128, 128, 3, padding=1),           #| \n",
    "            nn.BatchNorm2d(128,eps=0.001, momentum=0.99),#|\n",
    "            nn.ReLU(),                                   #|\n",
    "            nn.Conv2d(128, 128, 3, padding=1),           #| \n",
    "            nn.BatchNorm2d(128,eps=0.001, momentum=0.99),#|\n",
    "        )                                                #| \n",
    "    ),                                                   #|\n",
    "    nn.ReLU(),                                           #| \n",
    "    # ----------------------------------------------------| \n",
    "    \n",
    "    # ----------------------------------------------------| In code not paper |\n",
    "    ResBlock(                                            #|                   |\n",
    "        nn.Sequential(                                   #|                   | \n",
    "            nn.Conv2d(128, 128, 3, padding=1),           #|                   |\n",
    "            nn.BatchNorm2d(128,eps=0.001, momentum=0.99),#|                   |\n",
    "            nn.ReLU(),                                   #|                   |\n",
    "            nn.Conv2d(128, 128, 3, padding=1),           #|                   |\n",
    "            nn.BatchNorm2d(128,eps=0.001, momentum=0.99),#|                   |\n",
    "        )                                                #|                   |\n",
    "    ),                                                   #|                   |\n",
    "    nn.ReLU(),                                           #|                   |\n",
    "    # ----------------------------------------------------| In code not paper |\n",
    "    \n",
    "    # ----------------------------------------------------| In code not paper |\n",
    "    ResBlock(                                            #|                   |\n",
    "        nn.Sequential(                                   #|                   | \n",
    "            nn.Conv2d(128, 128, 3, padding=1),           #|                   |\n",
    "            nn.BatchNorm2d(128,eps=0.001, momentum=0.99),#|                   |\n",
    "            nn.ReLU(),                                   #|                   |\n",
    "            nn.Conv2d(128, 128, 3, padding=1),           #|                   |\n",
    "            nn.BatchNorm2d(128,eps=0.001, momentum=0.99),#|                   |\n",
    "        )                                                #|                   |\n",
    "    ),                                                   #|                   |\n",
    "    nn.ReLU(),                                           #|                   |\n",
    "    # ----------------------------------------------------| In code not paper | \n",
    "    Detection()\n",
    ")\n",
    "\n",
    "# print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the weights from keras into the pytorch model\n",
    "model[0].weight.data=torch.from_numpy(np.transpose(weights[0]))\n",
    "model[0].bias.data=torch.from_numpy(weights[1])\n",
    "model[1].weight.data=torch.from_numpy(weights[2])\n",
    "model[1].bias.data=torch.from_numpy(weights[3])\n",
    "model[1].running_mean.data=torch.from_numpy(weights[4])\n",
    "model[1].running_var.data=torch.from_numpy(weights[5])\n",
    "model[3].weight.data=torch.from_numpy(np.transpose(weights[6]))\n",
    "model[3].bias.data=torch.from_numpy(weights[7])\n",
    "model[4].weight.data=torch.from_numpy(weights[8])\n",
    "model[4].bias.data=torch.from_numpy(weights[9])\n",
    "model[4].running_mean.data=torch.from_numpy(weights[10])\n",
    "model[4].running_var.data=torch.from_numpy(weights[11])\n",
    "model[7].weight.data=torch.from_numpy(np.transpose(weights[12]))\n",
    "model[7].bias.data=torch.from_numpy(weights[13])\n",
    "model[8].weight.data=torch.from_numpy(weights[14])\n",
    "model[8].bias.data=torch.from_numpy(weights[15])\n",
    "model[8].running_mean.data=torch.from_numpy(weights[16])\n",
    "model[8].running_var.data=torch.from_numpy(weights[17])\n",
    "model[10].module[0].weight.data=torch.from_numpy(np.transpose(weights[18]))\n",
    "model[10].module[0].bias.data=torch.from_numpy(weights[19])\n",
    "model[10].module[1].weight.data=torch.from_numpy(weights[20])\n",
    "model[10].module[1].bias.data=torch.from_numpy(weights[21])\n",
    "model[10].module[1].running_mean.data=torch.from_numpy(weights[22])\n",
    "model[10].module[1].running_var.data=torch.from_numpy(weights[23])\n",
    "model[10].module[3].weight.data=torch.from_numpy(np.transpose(weights[24]))\n",
    "model[10].module[3].bias.data=torch.from_numpy(weights[25])\n",
    "model[10].module[4].weight.data=torch.from_numpy(weights[26])\n",
    "model[10].module[4].bias.data=torch.from_numpy(weights[27])\n",
    "model[10].module[4].running_mean.data=torch.from_numpy(weights[28])\n",
    "model[10].module[4].running_var.data=torch.from_numpy(weights[29])\n",
    "model[13].weight.data=torch.from_numpy(np.transpose(weights[30]))\n",
    "model[13].bias.data=torch.from_numpy(weights[31])\n",
    "model[14].weight.data=torch.from_numpy(weights[32])\n",
    "model[14].bias.data=torch.from_numpy(weights[33])\n",
    "model[14].running_mean.data=torch.from_numpy(weights[34])\n",
    "model[14].running_var.data=torch.from_numpy(weights[35])\n",
    "model[16].module[0].weight.data=torch.from_numpy(np.transpose(weights[36]))\n",
    "model[16].module[0].bias.data=torch.from_numpy(weights[37])\n",
    "model[16].module[1].weight.data=torch.from_numpy(weights[38])\n",
    "model[16].module[1].bias.data=torch.from_numpy(weights[39])\n",
    "model[16].module[1].running_mean.data=torch.from_numpy(weights[40])\n",
    "model[16].module[1].running_var.data=torch.from_numpy(weights[41])\n",
    "model[16].module[3].weight.data=torch.from_numpy(np.transpose(weights[42]))\n",
    "model[16].module[3].bias.data=torch.from_numpy(weights[43])\n",
    "model[16].module[4].weight.data=torch.from_numpy(weights[44])\n",
    "model[16].module[4].bias.data=torch.from_numpy(weights[45])\n",
    "model[16].module[4].running_mean.data=torch.from_numpy(weights[46])\n",
    "model[16].module[4].running_var.data=torch.from_numpy(weights[47])\n",
    "model[18].module[0].weight.data=torch.from_numpy(np.transpose(weights[48]))\n",
    "model[18].module[0].bias.data=torch.from_numpy(weights[49])\n",
    "model[18].module[1].weight.data=torch.from_numpy(weights[50])\n",
    "model[18].module[1].bias.data=torch.from_numpy(weights[51])\n",
    "model[18].module[1].running_mean.data=torch.from_numpy(weights[52])\n",
    "model[18].module[1].running_var.data=torch.from_numpy(weights[53])\n",
    "model[18].module[3].weight.data=torch.from_numpy(np.transpose(weights[54]))\n",
    "model[18].module[3].bias.data=torch.from_numpy(weights[55])\n",
    "model[18].module[4].weight.data=torch.from_numpy(weights[56])\n",
    "model[18].module[4].bias.data=torch.from_numpy(weights[57])\n",
    "model[18].module[4].running_mean.data=torch.from_numpy(weights[58])\n",
    "model[18].module[4].running_var.data=torch.from_numpy(weights[59])\n",
    "model[21].weight.data=torch.from_numpy(np.transpose(weights[60]))\n",
    "model[21].bias.data=torch.from_numpy(weights[61])\n",
    "model[22].weight.data=torch.from_numpy(weights[62])\n",
    "model[22].bias.data=torch.from_numpy(weights[63])\n",
    "model[22].running_mean.data=torch.from_numpy(weights[64])\n",
    "model[22].running_var.data=torch.from_numpy(weights[65])\n",
    "model[24].module[0].weight.data=torch.from_numpy(np.transpose(weights[66]))\n",
    "model[24].module[0].bias.data=torch.from_numpy(weights[67])\n",
    "model[24].module[1].weight.data=torch.from_numpy(weights[68])\n",
    "model[24].module[1].bias.data=torch.from_numpy(weights[69])\n",
    "model[24].module[1].running_mean.data=torch.from_numpy(weights[70])\n",
    "model[24].module[1].running_var.data=torch.from_numpy(weights[71])\n",
    "model[24].module[3].weight.data=torch.from_numpy(np.transpose(weights[72]))\n",
    "model[24].module[3].bias.data=torch.from_numpy(weights[73])\n",
    "model[24].module[4].weight.data=torch.from_numpy(weights[74])\n",
    "model[24].module[4].bias.data=torch.from_numpy(weights[75])\n",
    "model[24].module[4].running_mean.data=torch.from_numpy(weights[76])\n",
    "model[24].module[4].running_var.data=torch.from_numpy(weights[77])\n",
    "model[26].module[0].weight.data=torch.from_numpy(np.transpose(weights[78]))\n",
    "model[26].module[0].bias.data=torch.from_numpy(weights[79])\n",
    "model[26].module[1].weight.data=torch.from_numpy(weights[80])\n",
    "model[26].module[1].bias.data=torch.from_numpy(weights[81])\n",
    "model[26].module[1].running_mean.data=torch.from_numpy(weights[82])\n",
    "model[26].module[1].running_var.data=torch.from_numpy(weights[83])\n",
    "model[26].module[3].weight.data=torch.from_numpy(np.transpose(weights[84]))\n",
    "model[26].module[3].bias.data=torch.from_numpy(weights[85])\n",
    "model[26].module[4].weight.data=torch.from_numpy(weights[86])\n",
    "model[26].module[4].bias.data=torch.from_numpy(weights[87])\n",
    "model[26].module[4].running_mean.data=torch.from_numpy(weights[88])\n",
    "model[26].module[4].running_var.data=torch.from_numpy(weights[89])\n",
    "model[29].weight.data=torch.from_numpy(np.transpose(weights[90]))\n",
    "model[29].bias.data=torch.from_numpy(weights[91])\n",
    "model[30].weight.data=torch.from_numpy(weights[92])\n",
    "model[30].bias.data=torch.from_numpy(weights[93])\n",
    "model[30].running_mean.data=torch.from_numpy(weights[94])\n",
    "model[30].running_var.data=torch.from_numpy(weights[95])\n",
    "model[32].module[0].weight.data=torch.from_numpy(np.transpose(weights[96]))\n",
    "model[32].module[0].bias.data=torch.from_numpy(weights[97])\n",
    "model[32].module[1].weight.data=torch.from_numpy(weights[98])\n",
    "model[32].module[1].bias.data=torch.from_numpy(weights[99])\n",
    "model[32].module[1].running_mean.data=torch.from_numpy(weights[100])\n",
    "model[32].module[1].running_var.data=torch.from_numpy(weights[101])\n",
    "model[32].module[3].weight.data=torch.from_numpy(np.transpose(weights[102]))\n",
    "model[32].module[3].bias.data=torch.from_numpy(weights[103])\n",
    "model[32].module[4].weight.data=torch.from_numpy(weights[104])\n",
    "model[32].module[4].bias.data=torch.from_numpy(weights[105])\n",
    "model[32].module[4].running_mean.data=torch.from_numpy(weights[106])\n",
    "model[32].module[4].running_var.data=torch.from_numpy(weights[107])\n",
    "model[34].module[0].weight.data=torch.from_numpy(np.transpose(weights[108]))\n",
    "model[34].module[0].bias.data=torch.from_numpy(weights[109])\n",
    "model[34].module[1].weight.data=torch.from_numpy(weights[110])\n",
    "model[34].module[1].bias.data=torch.from_numpy(weights[111])\n",
    "model[34].module[1].running_mean.data=torch.from_numpy(weights[112])\n",
    "model[34].module[1].running_var.data=torch.from_numpy(weights[113])\n",
    "model[34].module[3].weight.data=torch.from_numpy(np.transpose(weights[114]))\n",
    "model[34].module[3].bias.data=torch.from_numpy(weights[115])\n",
    "model[34].module[4].weight.data=torch.from_numpy(weights[116])\n",
    "model[34].module[4].bias.data=torch.from_numpy(weights[117])\n",
    "model[34].module[4].running_mean.data=torch.from_numpy(weights[118])\n",
    "model[34].module[4].running_var.data=torch.from_numpy(weights[119])\n",
    "model[36].module[0].weight.data=torch.from_numpy(np.transpose(weights[120]))\n",
    "model[36].module[0].bias.data=torch.from_numpy(weights[121])\n",
    "model[36].module[1].weight.data=torch.from_numpy(weights[122])\n",
    "model[36].module[1].bias.data=torch.from_numpy(weights[123])\n",
    "model[36].module[1].running_mean.data=torch.from_numpy(weights[124])\n",
    "model[36].module[1].running_var.data=torch.from_numpy(weights[125])\n",
    "model[36].module[3].weight.data=torch.from_numpy(np.transpose(weights[126]))\n",
    "model[36].module[3].bias.data=torch.from_numpy(weights[127])\n",
    "model[36].module[4].weight.data=torch.from_numpy(weights[128])\n",
    "model[36].module[4].bias.data=torch.from_numpy(weights[129])\n",
    "model[36].module[4].running_mean.data=torch.from_numpy(weights[130])\n",
    "model[36].module[4].running_var.data=torch.from_numpy(weights[131])\n",
    "model[38].module[0].weight.data=torch.from_numpy(np.transpose(weights[132]))\n",
    "model[38].module[0].bias.data=torch.from_numpy(weights[133])\n",
    "model[38].module[1].weight.data=torch.from_numpy(weights[134])\n",
    "model[38].module[1].bias.data=torch.from_numpy(weights[135])\n",
    "model[38].module[1].running_mean.data=torch.from_numpy(weights[136])\n",
    "model[38].module[1].running_var.data=torch.from_numpy(weights[137])\n",
    "model[38].module[3].weight.data=torch.from_numpy(np.transpose(weights[138]))\n",
    "model[38].module[3].bias.data=torch.from_numpy(weights[139])\n",
    "model[38].module[4].weight.data=torch.from_numpy(weights[140])\n",
    "model[38].module[4].bias.data=torch.from_numpy(weights[141])\n",
    "model[38].module[4].running_mean.data=torch.from_numpy(weights[142])\n",
    "model[38].module[4].running_var.data=torch.from_numpy(weights[143])\n",
    "model[40].conv2.weight.data=torch.from_numpy(np.transpose(weights[144]))\n",
    "model[40].conv2.bias.data=torch.from_numpy(weights[145])\n",
    "model[40].conv6.weight.data=torch.from_numpy(np.transpose(weights[146]))\n",
    "model[40].conv6.bias.data=torch.from_numpy(weights[147])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('Plate_examples/germany_car_plate.jpg')\n",
    "print(img.size)\n",
    "plt.imshow(img.resize((845,600)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLabel (Label):\n",
    "\n",
    "\tdef __init__(self,cl,pts,prob):\n",
    "\t\tself.pts = pts\n",
    "\t\ttl = np.amin(pts,1)\n",
    "\t\tbr = np.amax(pts,1)\n",
    "\t\tLabel.__init__(self,cl,tl,br,prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't actually need to resize, I'm just doing it since that's the size they use in the paper\n",
    "model_img_size = 208\n",
    "model_noresize = transforms.ToTensor()\n",
    "model_transform = transforms.Compose([transforms.Resize((384,512)),\n",
    "                                         transforms.ToTensor()])\n",
    "img_input = model_transform(img)\n",
    "Iorig = model_noresize(img)\n",
    "print(img_input.shape,Iorig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "#Pass input through model\n",
    "img_input = img_input.to(device)\n",
    "Y = model(img_input.unsqueeze(0))[0]\n",
    "#Y[0] is probability of plate at x,y; Y[1] is probability of no plate at x,y\n",
    "#Y[2:] are the affine transformation parameters for every x,y\n",
    "#in alpr_unconstrained they first find the x,y locations above a certain threshold, then use the affine transformation there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_input.unsqueeze(0).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Probs = Y[0]\n",
    "Affines = Y[2:]\n",
    "xx, yy = torch.where(Probs > lp_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx,ry = Y.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_stride = 2**4\n",
    "side = ((208. + 40.)/2.)/net_stride # 7.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ywh = Y.shape[2:0:-1]\n",
    "WH = torch.tensor(img_input.shape[2:0:-1],dtype=torch.float)\n",
    "MN = WH/net_stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vxx = vyy = 0.5 #alpha\n",
    "\n",
    "base = lambda vx,vy: torch.tensor([[-vx,-vy,1.],[vx,-vy,1.],[vx,vy,1.],[-vx,vy,1.]]).T\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_size=(240,80)\n",
    "for i in range(len(xx)):\n",
    "    y,x = xx[i],yy[i]\n",
    "    affine = Affines[:,y,x].clone().detach()\n",
    "    prob = Probs[y,x]\n",
    "\n",
    "    mn = torch.tensor([float(x) + .5,float(y) + .5]).to(device)\n",
    "\n",
    "    A = affine.view((2,3))\n",
    "    A[0,0] = max(A[0,0],0.)\n",
    "    A[1,1] = max(A[1,1],0.)\n",
    "\n",
    "    pts = torch.mm(A,base(vxx,vyy)).clone().detach()\n",
    "    pts_MN_center_mn = pts*side\n",
    "    pts_MN = pts_MN_center_mn + mn.view((2,1))\n",
    "\n",
    "    pts_prop = pts_MN/MN.view((2,1))\n",
    "    labels.append(DLabel(0,pts_prop.numpy(),prob))\n",
    "\n",
    "final_labels = nms(labels,.1)\n",
    "TLps = []\n",
    "\n",
    "if len(final_labels):\n",
    "    final_labels.sort(key=lambda x: x.prob(), reverse=True)\n",
    "    for i,label in enumerate(final_labels):\n",
    "\n",
    "        t_ptsh \t= getRectPts(0,0,out_size[0],out_size[1])\n",
    "        ptsh \t= np.concatenate((label.pts*getWH(Iorig.permute(1,2,0).shape).reshape((2,1)),np.ones((1,4))))\n",
    "        H \t\t= find_T_matrix(ptsh,t_ptsh)\n",
    "        Ilp \t= cv2.warpPerspective(np.float32(Iorig.permute(1,2,0).numpy()),H,out_size,borderValue=.0)\n",
    "\n",
    "        TLps.append(Ilp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(TLps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
