{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_model import load_wpod\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms, utils, models\n",
    "from torch import nn\n",
    "import torch\n",
    "from src.label import Label, Shape\n",
    "from src.utils import getWH, nms, im2single, IOU_centre_and_dims\n",
    "from src.projection_utils import getRectPts, find_T_matrix\n",
    "import time\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import traceback\n",
    "\n",
    "import darknet.python.darknet as dn\n",
    "\n",
    "from os.path \t\t\t\timport splitext, basename\n",
    "from glob\t\t\t\t\timport glob\n",
    "from darknet.python.darknet import detect\n",
    "from src.label\t\t\t\timport dknet_label_conversion\n",
    "from src.utils \t\t\t\timport nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_to_tensor = transforms.ToTensor()\n",
    "tensor_to_pil = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLabel (Label):\n",
    "\n",
    "    def __init__(self,cl,pts,prob):\n",
    "        self.pts = pts\n",
    "        tl = np.amin(pts,1)\n",
    "        br = np.amax(pts,1)\n",
    "        Label.__init__(self,cl,tl,br,prob)\n",
    "\n",
    "\n",
    "def reconstruct(Iorig,I,Y,out_size,threshold=.9):\n",
    "\n",
    "    net_stride \t= 2**4\n",
    "    side = ((208. + 40.)/2.)/net_stride # 7.75\n",
    "    \n",
    "    Probs = Y[...,0]\n",
    "    Affines = Y[...,2:]\n",
    "    rx,ry = Y.shape[:2]\n",
    "    ywh = Y.shape[1::-1]\n",
    "    iwh = np.array(I.shape[1::-1],dtype=float).reshape((2,1))\n",
    "    xx,yy = np.where(Probs>threshold)\n",
    "    \n",
    "    WH = getWH(I.shape)\n",
    "    MN = WH/net_stride\n",
    "\n",
    "    vxx = vyy = 0.5 #alpha\n",
    "\n",
    "    base = lambda vx,vy: np.matrix([[-vx,-vy,1.],[vx,-vy,1.],[vx,vy,1.],[-vx,vy,1.]]).T\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(xx)):\n",
    "        y,x = xx[i],yy[i]\n",
    "        affine = Affines[y,x]\n",
    "        prob = Probs[y,x]\n",
    "        mn = np.array([float(x) + .5,float(y) + .5])\n",
    "        A = np.reshape(affine,(2,3))\n",
    "        A[0,0] = max(A[0,0],0.)\n",
    "        A[1,1] = max(A[1,1],0.)\n",
    "        pts = np.array(A*base(vxx,vyy)) #*alpha\n",
    "        pts_MN_center_mn = pts*side\n",
    "        pts_MN = pts_MN_center_mn + mn.reshape((2,1))\n",
    "\n",
    "        pts_prop = pts_MN/MN.reshape((2,1))\n",
    "\n",
    "        labels.append(DLabel(0,pts_prop,prob))\n",
    "\n",
    "    final_labels = nms(labels,.1)\n",
    "    TLps = []\n",
    "\n",
    "    if len(final_labels):\n",
    "        final_labels.sort(key=lambda x: x.prob(), reverse=True)\n",
    "        for i,label in enumerate(final_labels):\n",
    "\n",
    "            t_ptsh \t= getRectPts(0,0,out_size[0],out_size[1])\n",
    "            ptsh \t= np.concatenate((label.pts*getWH(Iorig.shape).reshape((2,1)),np.ones((1,4))))\n",
    "            H \t\t= find_T_matrix(ptsh,t_ptsh)\n",
    "            Ilp \t= cv2.warpPerspective(Iorig,H,out_size,borderValue=.0)\n",
    "\n",
    "            TLps.append(Ilp)\n",
    "\n",
    "    return final_labels,TLps\n",
    "    \n",
    "\n",
    "def detect_lp(model,I,max_dim,net_step,out_size,threshold,masked_pattern=None,train=None):\n",
    "\n",
    "    min_dim_img = min(I.shape[:2])\n",
    "    factor \t\t= float(max_dim)/min_dim_img\n",
    "\n",
    "    w,h = (np.array(I.shape[1::-1],dtype=float)*factor).astype(int).tolist()\n",
    "    w += (w%net_step!=0)*(net_step - w%net_step)\n",
    "    h += (h%net_step!=0)*(net_step - h%net_step)\n",
    "    Iresized = cv2.resize(I,(w,h))\n",
    "    print(Iresized.shape)\n",
    "    Tn = Iresized.copy()\n",
    "    Tn = Tn.reshape((1,Tn.shape[0],Tn.shape[1],Tn.shape[2]))\n",
    "    Tn = torch.tensor(Tn, device=device).permute(0,3,1,2)\n",
    "    #display(tensor_to_pil(Tn.cpu()[0]))\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    if masked_pattern is not None:\n",
    "        Tn = masked_pattern*Tn\n",
    "    if train:\n",
    "        Yr = model(Tn).permute(0,2,3,1)\n",
    "        return None,None,None,Yr,Tn\n",
    "    else:\n",
    "        display(tensor_to_pil(Tn.cpu()[0]))\n",
    "        Yr = model(Tn).permute(0,2,3,1)\n",
    "        Y2 = np.squeeze(Yr)\n",
    "        Y2 = Y2.cpu().detach().numpy()\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    L,TLps = reconstruct(I,Iresized,Y2,out_size,threshold)\n",
    "\n",
    "    return L,TLps,elapsed,Yr.cpu(),Tn\n",
    "    \n",
    "def getResizedImage(I,max_dim,net_step):\n",
    "    min_dim_img = min(I.shape[:2])\n",
    "    factor \t\t= float(max_dim)/min_dim_img\n",
    "\n",
    "    w,h = (np.array(I.shape[1::-1],dtype=float)*factor).astype(int).tolist()\n",
    "    w += (w%net_step!=0)*(net_step - w%net_step)\n",
    "    h += (h%net_step!=0)*(net_step - h%net_step)\n",
    "    Iresized = cv2.resize(I,(w,h))\n",
    "    return Iresized\n",
    "\n",
    "def augment_sample(I,pts,dim):\n",
    "\n",
    "\tmaxsum,maxangle = 120,np.array([80.,80.,45.])\n",
    "\tangles = np.random.rand(3)*maxangle\n",
    "\tif angles.sum() > maxsum:\n",
    "\t\tangles = (angles/angles.sum())*(maxangle/maxangle.sum())\n",
    "\n",
    "\tI = im2single(I)\n",
    "\tiwh = getWH(I.shape)\n",
    "\n",
    "\twhratio = random.uniform(2.,4.)\n",
    "\twsiz = random.uniform(dim*.2,dim*1.)\n",
    "\t\n",
    "\thsiz = wsiz/whratio\n",
    "\n",
    "\tdx = random.uniform(0.,dim - wsiz)\n",
    "\tdy = random.uniform(0.,dim - hsiz)\n",
    "\n",
    "\tpph = getRectPts(dx,dy,dx+wsiz,dy+hsiz)\n",
    "\tpts = pts*iwh.reshape((2,1))\n",
    "\tT = find_T_matrix(pts2ptsh(pts),pph)\n",
    "\n",
    "\tH = perspective_transform((dim,dim),angles=angles)\n",
    "\tH = np.matmul(H,T)\n",
    "\n",
    "\tIroi,pts = project(I,H,pts,dim)\n",
    "\t\n",
    "\thsv_mod = np.random.rand(3).astype('float32')\n",
    "\thsv_mod = (hsv_mod - .5)*.3\n",
    "\thsv_mod[0] *= 360\n",
    "\tIroi = hsv_transform(Iroi,hsv_mod)\n",
    "\tIroi = np.clip(Iroi,0.,1.)\n",
    "\n",
    "\tpts = np.array(pts)\n",
    "\n",
    "\tif random.random() > .5:\n",
    "\t\tIroi,pts = flip_image_and_pts(Iroi,pts)\n",
    "\n",
    "\ttl,br = pts.min(1),pts.max(1)\n",
    "\tllp = Label(0,tl,br)\n",
    "\n",
    "\treturn Iroi,llp,pts\n",
    "\n",
    "def l1(true,pred,szs):\n",
    "\tb,h,w,ch = szs\n",
    "\tres = torch.reshape(true-pred,(b,h*w*ch))\n",
    "\tres = torch.abs(res)\n",
    "\tres = torch.sum(res,1)\n",
    "\treturn res\n",
    "\n",
    "def logloss(Ptrue,Pred,szs,eps=10e-10):\n",
    "\tb,h,w,ch = szs\n",
    "\tPred = torch.clamp(Pred,eps,1.)\n",
    "\tPred = -torch.log(Pred)\n",
    "\tPred = Pred*Ptrue\n",
    "\tPred = torch.reshape(Pred,(b,h*w*ch))\n",
    "\tPred = torch.sum(Pred,1)\n",
    "\treturn Pred\n",
    "\n",
    "def total_loss(Ytrue, Ypred):\n",
    "\n",
    "    b = Ytrue.size()[0]\n",
    "    h = Ytrue.size()[1]\n",
    "    w = Ytrue.size()[2]\n",
    "\n",
    "    obj_probs_true = Ytrue[...,0]\n",
    "    obj_probs_pred = Ypred[...,0]\n",
    "\n",
    "    #print((obj_probs_true>0).nonzero())\n",
    "    #print((obj_probs_pred>0.5).nonzero())\n",
    "    #print(obj_probs_true[obj_probs_true>0],obj_probs_pred[obj_probs_true>0])\n",
    "    #print(obj_probs_true[obj_probs_pred>0.5],obj_probs_pred[obj_probs_pred>0.5])\n",
    "    \n",
    "    non_obj_probs_true = 1. - Ytrue[...,0]\n",
    "    non_obj_probs_pred = Ypred[...,1]\n",
    "\n",
    "    affine_pred\t= Ypred[...,2:]\n",
    "    pts_true \t= Ytrue[...,1:]\n",
    "\n",
    "    affine_pred[...,0][affine_pred[...,0]<0] = 0\n",
    "    affine_pred[...,4][affine_pred[...,4]<0] = 0\n",
    "    affinex = torch.stack([affine_pred[...,0],affine_pred[...,1],affine_pred[...,2]],3)\n",
    "    affiney = torch.stack([affine_pred[...,3],affine_pred[...,4],affine_pred[...,5]],3)\n",
    "    v = 0.5\n",
    "    base = torch.tensor([[[[-v,-v,1., v,-v,1., v,v,1., -v,v,1.]]]],device=device)\n",
    "    base = base.repeat(b,h,w,1)\n",
    "    pts = torch.zeros((b,h,w,0),device=device)\n",
    "\n",
    "    for i in range(0,12,3):\n",
    "        row = base[...,i:(i+3)]\n",
    "        ptsx = torch.sum(affinex*row,3)\n",
    "        ptsy = torch.sum(affiney*row,3)\n",
    "\n",
    "        pts_xy = torch.stack([ptsx,ptsy],3)\n",
    "        pts = (torch.cat([pts,pts_xy],3))\n",
    "\n",
    "    flags = torch.reshape(obj_probs_true,(b,h,w,1))\n",
    "    res   = 1.*l1(pts_true*flags,pts*flags,(b,h,w,4*2))\n",
    "    res  += 1.*logloss(obj_probs_true,obj_probs_pred,(b,h,w,1))\n",
    "    res  += 1.*logloss(non_obj_probs_true,non_obj_probs_pred,(b,h,w,1))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels2output_map(label,lppts,dim,stride):\n",
    "\n",
    "    #side = ((float(dim) + 40.)/2.)/stride # 7.75 when dim = 208 and stride = 16\n",
    "    \n",
    "    side = 7.75\n",
    "    \n",
    "    outsize1, outsize2 = int(dim[0]/stride), int(dim[1]/stride)\n",
    "    Y  = np.zeros((outsize1,outsize2,2*4+1),dtype='float32')\n",
    "    MN = np.array([outsize1,outsize2])\n",
    "    WH = np.array([dim[0],dim[1]],dtype=float)\n",
    "\n",
    "    tlx,tly = np.floor(np.maximum(label.tl(),0.)*MN).astype(int).tolist()\n",
    "    brx,bry = np.ceil (np.minimum(label.br(),1.)*MN).astype(int).tolist()\n",
    "\n",
    "    for x in range(tlx,brx):\n",
    "        for y in range(tly,bry):\n",
    "\n",
    "            mn = np.array([float(x) + .5, float(y) + .5])\n",
    "            iou = IOU_centre_and_dims(mn/MN,label.wh(),label.cc(),label.wh())\n",
    "\n",
    "            if iou > .5:\n",
    "\n",
    "                p_WH = lppts*WH.reshape((2,1))\n",
    "                p_MN = p_WH/stride\n",
    "\n",
    "                p_MN_center_mn = p_MN - mn.reshape((2,1))\n",
    "\n",
    "                p_side = p_MN_center_mn/side\n",
    "\n",
    "                Y[x,y,0] = 1.\n",
    "                Y[x,y,1:] = p_side.T.flatten()\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_pts(pts,lroi):\n",
    "\treturn pts*lroi.wh().reshape((2,1)) + lroi.tl().reshape((2,1))\n",
    "\n",
    "\n",
    "output_dir = \"./temp\"\n",
    "\n",
    "lp_threshold = .5\n",
    "\n",
    "wpod_net = load_wpod()\n",
    "wpod_net.to(device)\n",
    "wpod_net.eval()\n",
    "print('Searching for license plates using WPOD-NET')\n",
    "\n",
    "tvehicle = cv2.imread('Plate_examples/lp_white_new.jpg')\n",
    "#tvehicle = cv2.resize(tvehicle,(208,208))\n",
    "#Ivehicle = Ivehicle[450:630, 480:1170]\n",
    "plt.imshow(tvehicle)\n",
    "print(tvehicle.shape)\n",
    "#Ivehicle = cv2.bitwise_and(Ivehicle, Ivehicle, mask=cv2.bitwise_not(get_mask(Ivehicle)))\n",
    "ratio = float(max(tvehicle.shape[:2]))/min(tvehicle.shape[:2])\n",
    "side  = int(ratio*288.)\n",
    "bound_dim = min(side + (side%(2**4)),608)\n",
    "print(\"\\t\\tBound dim: %d, ratio: %f\" % (bound_dim,ratio)) \n",
    "\n",
    "Llp,LlpImgs,_,Y3,_ = detect_lp(wpod_net,im2single(tvehicle),bound_dim,2**4,(240,80),lp_threshold)\n",
    "\n",
    "if len(LlpImgs):\n",
    "    print('found')\n",
    "    Ilp = LlpImgs[0]\n",
    "    Ilp = cv2.cvtColor(Ilp, cv2.COLOR_BGR2GRAY)\n",
    "    Ilp = cv2.cvtColor(Ilp, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    s = Shape(Llp[0].pts)\n",
    "    cv2.imwrite('./temp/lp.jpg',255*Ilp)\n",
    "    plt.imshow(Ilp)\n",
    "print(Y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl,br = s.pts.min(1),s.pts.max(1)\n",
    "llp = Label(0,tl,br)\n",
    "print(tl,br)\n",
    "Y = labels2output_map(llp,s.pts,(512,912),16)\n",
    "Y = torch.tensor(Y)\n",
    "Y = Y.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y3 = Y3.to(device)\n",
    "Y = Y.to(device)\n",
    "print(Y.size(), Y3.size())\n",
    "total_loss(Y,Y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tmn(Yr):\n",
    "    Tmn = torch.ones([Yr.size()[0],Yr.size()[1],Yr.size()[2],8])\n",
    "    Yr[...,2][Yr[...,2]<0]=0\n",
    "    Yr[...,5][Yr[...,5]<0]=0\n",
    "    Tmn[...,0]= Yr[...,2]*-0.5+Yr[...,3]*-0.5+Yr[...,6]\n",
    "    Tmn[...,1]= Yr[...,4]*-0.5+Yr[...,5]*-0.5+Yr[...,7]\n",
    "    Tmn[...,2]= Yr[...,2]*0.5+Yr[...,3]*-0.5+Yr[...,6]\n",
    "    Tmn[...,3]= Yr[...,4]*0.5+Yr[...,5]*-0.5+Yr[...,7]\n",
    "    Tmn[...,4]= Yr[...,2]*0.5+Yr[...,3]*0.5+Yr[...,6]\n",
    "    Tmn[...,5]= Yr[...,4]*0.5+Yr[...,5]*0.5+Yr[...,7]\n",
    "    Tmn[...,6]= Yr[...,2]*-0.5+Yr[...,3]*0.5+Yr[...,6]\n",
    "    Tmn[...,7]= Yr[...,4]*-0.5+Yr[...,5]*0.5+Yr[...,7]\n",
    "    return Tmn\n",
    "def get_affine_loss(Y,Yr):\n",
    "    Y = torch.tensor(Y)\n",
    "    a = torch.sum(torch.abs(Tmn(Yr)-Y[...,1:]),axis=-1)\n",
    "    L_affine = Y[...,0]*a\n",
    "    return torch.sum(torch.sum(L_affine,dim=1),dim=1)\n",
    "print(Y.shape, Y3.shape)\n",
    "temp = Tmn(Y3)\n",
    "print(temp[0][0][0][1], Y[7][7][0], Y[7][7][2])\n",
    "get_affine_loss(Y,Y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(Ivehicle,h=None,w=None,d=None):\n",
    "    if h:\n",
    "        height,width,depth = h,w,d\n",
    "    else: height,width,depth = Ivehicle.shape\n",
    "    x = Ivehicle.copy()\n",
    "    x = cv2.resize(x,(height,width))\n",
    "    circle_img = np.zeros((height,width), np.uint8)\n",
    "    #cv2.rectangle(circle_img,(86,107),(212,152),280,thickness=-1)\n",
    "    #cv2.rectangle(circle_img,(86,107),(212,152),280,thickness=-1)\n",
    "    print(circle_img.shape)\n",
    "    #circle_img = circle_img.reshape((1,circle_img.shape[0],circle_img.shape[1]))\n",
    "    #circle_img = torch.tensor(circle_img).permute(0,1,2)\n",
    "    #cv2.rectangle(circle_img,(480,480),(1170,570),255,thickness=-1)\n",
    "    plt.imshow(cv2.bitwise_and(x, x, mask=circle_img))\n",
    "    return circle_img\n",
    "get_mask(tvehicle,288,288,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_resize = True\n",
    "repeat_size=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For resize post convolution\n",
    "if account_resize:\n",
    "    repeat_size = int(3024/3024)\n",
    "    img = Ivehicle.resize((208,208))\n",
    "    model_img_size = img.size[0]\n",
    "    img_t = pil_to_tensor(img)\n",
    "    img_t = img_t.to(device)\n",
    "    def resize2d(img, size):\n",
    "        return (F.adaptive_avg_pool2d(Variable(img), size)).data\n",
    "    def upsample2d(img, size=224):\n",
    "        upsample = nn.Upsample(size=size, mode='bilinear', align_corners=False)\n",
    "        return upsample(torch.unsqueeze(img, 0))[0]\n",
    "else:\n",
    "    model_img_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_img_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical exposure is in form 1/n s. Available: 15, 20, 25 30, 40, 50, 60, 80, 100, 125, 160, 200, 250\n",
    "exposure = 1000\n",
    "exp_micros = 1000000/exposure          # get exposure in microseconds\n",
    "img_ratio = 2268 / model_img_size      # every row in model is img_ratio rows in original image\n",
    "model_tr = 10 * img_ratio              # multiply real tr (10 micros) by img_ratio to find model tr\n",
    "conv_size = exp_micros / model_tr      # divide exposure time by tr to find convolution size\n",
    "conv_size = int(conv_size)             # Need closest integer approximation. Won't cause a significant difference\n",
    "conv_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ivehicle = cv2.imread('Plate_examples/lptest.jpg')\n",
    "r = cv2.imread('Plate_examples/lp_red.jpg')\n",
    "g = cv2.imread('Plate_examples/lp_green.jpg')\n",
    "b = cv2.imread('Plate_examples/lp_blue.jpg')\n",
    "white = cv2.imread('Plate_examples/lp_white_new.jpg')\n",
    "canvas = np.zeros([2268,4032,3],dtype=np.uint8)\n",
    "canvas[:,:,0] = b[:,:,0]\n",
    "canvas[:,:,1] = g[:,:,1]\n",
    "canvas[:,:,2] = r[:,:,2]\n",
    "Ivehicle = white\n",
    "#Ivehicle = cv2.resize(Ivehicle,(208,208))\n",
    "print(Ivehicle.shape)\n",
    "plt.imshow(white)\n",
    "#print(w)\n",
    "#print(torch.tensor(r).shape)\n",
    "#display(tensor_to_pil(torch.tensor(w).permute(2,0,1)))\n",
    "#Ivehicle = cv2.cvtColor(Ivehicle, cv2.COLOR_BGR2RGB)\n",
    "#Ivehicle = cv2.resize(Ivehicle,(208,208))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = model_img_size + conv_size - 1 # 300   #Length of input signal\n",
    "c = 0    #Ambient light ratio\n",
    "c_limits = [0,0]\n",
    "batch = 8\n",
    "channels = 3\n",
    "# change of variable term to optimise on\n",
    "w = torch.rand([channels,sz,1], requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "#Create the mask to only illuminate the object\n",
    "#mask = torch.tensor(get_mask(Ivehicle,288,288,3), dtype=torch.float, device=device)\n",
    "#mask = torch.tensor(get_mask(Ivehicle,288,288,3), device=device)\n",
    "mask = torch.ones([3,512,912], device=device)\n",
    "mask = mask / torch.max(mask)\n",
    "#mask = get_mask(Ivehicle,288,288,3)\n",
    "\n",
    "#Target and original class labels\n",
    "#orig = torch.tensor([classidx], dtype=torch.long, device=device)\n",
    "\n",
    "#Model parameters\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "optimizer = optim.SGD([w], lr=lr, momentum=0.9, nesterov=True)\n",
    "#optimizer = optim.Adam([w], lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelf = torch.flatten(torch.tensor(Y[...,0], dtype=torch.float, device=device))\n",
    "labelnf = torch.flatten(torch.tensor(1-Y[...,0], dtype=torch.float, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_run(update_frequency, print_frequency, n_epochs, image):\n",
    "    #Track the loss to target and original class\n",
    "    loss_list = []\n",
    "\n",
    "    #obj_dict = {}\n",
    "    #w = -1*w\n",
    "    #Optimisation loop. initially untargeted\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "\n",
    "        if channels==1:\n",
    "            n_w = w.repeat(3,1,1)\n",
    "        else:\n",
    "            n_w = w\n",
    "            \n",
    "        #with torch.no_grad():\n",
    "        #    torch.clamp_(n_w, min=-0.3)\n",
    "        # For resize post convolution\n",
    "        #if account_resize:\n",
    "        #    n_w = torch.repeat_interleave(n_w, repeats=repeat_size, dim=1)\n",
    "        \n",
    "        sig_height = model_img_size + conv_size - 1\n",
    "        gy, new_w = fttogy(n_w, batch, None, c_limits, sig_height, conv_size, 0, shifting=True)\n",
    "\n",
    "        #with torch.no_grad():\n",
    "        #    torch.clamp_(gy, min=0.1)\n",
    "        #pattern = 1-mask + torch.mul(gy,mask)\n",
    "        #new_w.retain_grad()\n",
    "        #gy.retain_grad()\n",
    "        #with torch.autograd.set_detect_anomaly(True):\n",
    "        #Llp,LlpImgs,x,Yr,T = detect_lp(wpod_net,im2single(Ivehicle),bound_dim,2**4,(240,80),lp_threshold,gy,train=True)\n",
    "        Tn = gy*image\n",
    "        Yr = wpod_net(Tn).permute(0,2,3,1)\n",
    "        #Yr.retain_grad()\n",
    "        #loss = torch.sum(torch.stack([Yr[i][...,0][np.where(Y[...,0]>0.5)] for i in range(Yr.size()[0])]**2))\n",
    "        \n",
    "        loss = (torch.max(torch.max(Yr[:,:,:,0],dim=1)[0],dim=1)[0])**2\n",
    "        loss = torch.sum(loss[loss>0.25])\n",
    "        \n",
    "        loss = -1*torch.sum(total_loss(Y,Yr))\n",
    "        #print(make_dot(new_w))\n",
    "        #loss.retain_grad()\n",
    "        if epoch%print_frequency==0:\n",
    "            #print(Yr[...,0][np.where(Y[...,0]>0.5)])\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "        loss.backward()\n",
    "\n",
    "        if epoch%max(100,update_frequency)==0:\n",
    "            #print(Yr[...,0][np.where(Y[...,0]>0.5)])\n",
    "            #print(w.grad[0][:5], w.grad[1][:5], w.grad[2][:5])\n",
    "            #print(w[0][:5],w[1][:5],w[2][:5])\n",
    "            print(loss) \n",
    "            print(total_loss(Y,Yr))\n",
    "            print(torch.max(torch.max(Yr[:,:,:,0],dim=1)[0],dim=1)[0])\n",
    "\n",
    "        if epoch%update_frequency==0:\n",
    "            #print('loss_grad',loss.grad)\n",
    "            #print('gy_grad', gy.grad[gy.grad>0])\n",
    "            #print('w_grad', w.grad)\n",
    "            #print('new_w', new_w.grad[new_w.grad>0])\n",
    "            #print(w.grad[0][:5])#, w.grad[1][:5], w.grad[2][:5])\n",
    "            #print(w[0][:5],w[1][:5],w[2][:5])\n",
    "            optimizer.step()\n",
    "            #with torch.no_grad():\n",
    "            #    torch.clamp_(w, min=-1)\n",
    "            optimizer.zero_grad()\n",
    "            del loss\n",
    "            torch.cuda.empty_cache()\n",
    "        #if epoch!=n_epochs-1:\n",
    "        #    del inp\n",
    "        #    del new_w\n",
    "        #else:\n",
    "            #saving w to be used for prediction\n",
    "            #torch.save(n_w,'w_0.5_764.pt')\n",
    "\n",
    "        #Code to check gpu allocation    \n",
    "        '''\n",
    "        for obj in gc.get_objects():\n",
    "            try:\n",
    "                if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "                    #print(type(obj), obj.size())\n",
    "                    if type(obj) not in obj_dict:\n",
    "                        obj_dict[type(obj)] = 1\n",
    "                    else:\n",
    "                        obj_dict[type(obj)] += 1\n",
    "            except: pass\n",
    "        print(obj_dict)\n",
    "        obj_dict.clear()\n",
    "        '''\n",
    "    return loss_list, Yr, gy, new_w, Tn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iresized = getResizedImage(im2single(Ivehicle),bound_dim,2**4)\n",
    "Tn = Iresized.copy()\n",
    "Tn = Tn.reshape((1,Tn.shape[0],Tn.shape[1],Tn.shape[2]))\n",
    "Tn = torch.tensor(Tn, device=device).permute(0,3,1,2)\n",
    "#display(tensor_to_pil(Tn.cpu()[0]))\n",
    "print(Y.size())\n",
    "if Y.size()[0]==1:\n",
    "    Y = Y.repeat(8,1,1,1)\n",
    "Y = Y.to(device)\n",
    "print(Y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View original loss and target loss\n",
    "update_freqs = [10]\n",
    "result = []\n",
    "for up in update_freqs:\n",
    "    '''\n",
    "    t = np.full((channels,500,1),-0)\n",
    "    for c in range(3):\n",
    "        for ind in range(500):\n",
    "            t[c][ind][0] = ((c+int(ind/10))%10)-5\n",
    "    w = torch.tensor(t, requires_grad=True, dtype=torch.float, device=device)\n",
    "    '''\n",
    "    #w = torch.rand([channels,100,1], requires_grad=True, dtype=torch.float, device=device)\n",
    "    #optimizer = optim.SGD([w], lr=100, momentum=0.9, nesterov=True)\n",
    "    optimizer = optim.Adam([w], lr=0.5)\n",
    "    result.append(train_run(up, 10, 500, Tn))\n",
    "    plt.plot([x.item() for x in result[-1][0]], label=str(up))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = result[0][4][4].cpu().detach().numpy().transpose(1, 2, 0)\n",
    "print(image.shape)\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(batch):\n",
    "    print(i)\n",
    "    #print(torch.mean(result[0][1][i][:,:,0][np.where(Y[:,:,0]>0.5)]).item())\n",
    "    print(result[0][1][i][:,:,0][result[0][1][i][:,:,0]>0.5].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = result[0][2][0].repeat(1,1,912).cpu().detach().numpy().transpose(1, 2, 0)\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(result[0][3],'Plate_examples/size_500_rand_w_clamp_1.pt')\n",
    "plt.plot(torch.flatten(result[0][3][0][0]).detach().cpu(), label=\"w_b\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(torch.flatten(result[0][3][0][1]).detach().cpu(), label=\"w_g\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(torch.flatten(result[0][3][0][2]).detach().cpu(), label=\"w_r\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Llp,LlpImgs,_,Y2,_ = detect_lp(wpod_net,im2single(Ivehicle),bound_dim,2**4,(240,80),lp_threshold,result[0][2][2:3])\n",
    "print(Y2[...,0][Y2[...,0]>0.1])\n",
    "if len(LlpImgs):\n",
    "    print('found')\n",
    "    Ilp = LlpImgs[0]\n",
    "    Ilp = cv2.cvtColor(Ilp, cv2.COLOR_BGR2GRAY)\n",
    "    Ilp = cv2.cvtColor(Ilp, cv2.COLOR_GRAY2BGR)\n",
    "    #Ilp = cv2.cvtColor(Ilp, cv2.COLOR_BGR2RGB)\n",
    "    s = Shape(Llp[0].pts)\n",
    "    cv2.imwrite('./temp/lp.jpg',255*Ilp)\n",
    "    plt.imshow(Ilp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y2[...,0][np.where(Y2[...,0]>0.5)])\n",
    "print(torch.max(torch.max(Y2[:,:,:,0],dim=1)[0],dim=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyMask(new_w, batch_limits, mask, c_limits, sig_height, conv_size, precision_depth=2):\n",
    "    \n",
    "    lay = torch.nn.Conv1d(1,1,conv_size)\n",
    "\n",
    "    #Manually setting the weights and bias so the  shutter acts as a box filter\n",
    "    lay.weight.data = torch.full([1,1,conv_size,1], 1/conv_size, requires_grad=True, dtype=torch.float, device=device)\n",
    "    lay.bias.data = torch.zeros(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "    \n",
    "    sz = new_w.shape[1]\n",
    "    batch = batch_limits[1]-batch_limits[0]\n",
    "    #stack the signal to fit the input size\n",
    "    new_w = stack(new_w,sig_height)             \n",
    "    \n",
    "    # EOT sampling for ambient light and shift\n",
    "    c = torch.rand([batch,1,1,1], device=device) * (c_limits[1] - c_limits[0]) + c_limits[0]\n",
    "    shift = torch.tensor(range(batch_limits[0],batch_limits[1]), dtype=torch.int)\n",
    "    #shift = torch.from_numpy(np.array(range(0,batch,1)))\n",
    "    \n",
    "    #Shift the signal\n",
    "    new_w = shift_operation(new_w.unsqueeze(0).repeat(batch,1,1,1).view(-1, sig_height, 1), shift).view(batch,3,sig_height,1)\n",
    "    \n",
    "    #Fit w into the range [0,1]. new_w is the same as ft\n",
    "    #new_w = .5 * (torch.tanh(ootn) + 1)\n",
    "    \n",
    "    #precision limit\n",
    "    new_w = diff_round(new_w, precision_depth)\n",
    "    \n",
    "    #Convolution of ft and the shutter\n",
    "    #gy = lay(new_w.unsqueeze(0).view([3,1,228,batch])).view([batch,3,224,1])\n",
    "    gy = lay(new_w.transpose(0,3).transpose(0,1)).transpose(0,1).transpose(0,3)\n",
    "\n",
    "    #Mask the signal to only affect the object\n",
    "    if mask:\n",
    "        gy_mask = torch.mul(gy,torch.transpose(mask,1,0))\n",
    "    else:\n",
    "        gy_mask = gy\n",
    "\n",
    "    return (c + (1-c)*gy_mask), c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ocr(count):\n",
    "    ocr_threshold = .4\n",
    "\n",
    "    ocr_weights = bytes('data/ocr/ocr-net.weights', encoding=\"utf-8\")\n",
    "    ocr_netcfg  = bytes('data/ocr/ocr-net.cfg', encoding=\"utf-8\")\n",
    "    ocr_dataset = bytes('data/ocr/ocr-net.data', encoding=\"utf-8\")\n",
    "\n",
    "    ocr_net  = dn.load_net(ocr_netcfg, ocr_weights, 0)\n",
    "    ocr_meta = dn.load_meta(ocr_dataset)\n",
    "\n",
    "    imgs_path = bytes('./temp/lp'+str(count)+'.jpg', encoding=\"utf-8\")\n",
    "\n",
    "    bname = basename(splitext(img_path)[0])\n",
    "\n",
    "    R = detect(ocr_net, ocr_meta, imgs_path ,thresh=ocr_threshold, nms=None)\n",
    "\n",
    "    if len(R):\n",
    "\n",
    "        L = dknet_label_conversion(R,240,80)\n",
    "        L = nms(L,.45)\n",
    "\n",
    "        L.sort(key=lambda x: x.tl()[0])\n",
    "        lp_str = ''.join([chr(l.cl()) for l in L])\n",
    "\n",
    "        return lp_str\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = result[0][3]#torch.load('Plate_examples/size_100_init_striped_input_white_clamp_0.pt', map_location=torch.device('cpu'))\n",
    "#w = torch.ones(w.size())\n",
    "ww = ww.to(device)\n",
    "ww = ww[0]\n",
    "sig_height = model_img_size + conv_size - 1\n",
    "max_accuracies = []\n",
    "recovered_characters = []\n",
    "for i in range(0,100,5): \n",
    "    gy, c = applyMask(ww, [i,i+5], None, [0,0], sig_height, conv_size, 0)\n",
    "    Yr = wpod_net(gy*Tn).permute(0,2,3,1)\n",
    "    max_accuracies += list(torch.max(torch.max(Yr[:,:,:,0],dim=1)[0],dim=1)[0].cpu().detach().numpy())\n",
    "    for i in range(Yr.size()[0]):\n",
    "        L,TLps = reconstruct(Ivehicle,getResizedImage(im2single(Ivehicle),bound_dim,2**4),Yr[i].cpu().detach().numpy(),(240,80),0.5)\n",
    "        if len(TLps):\n",
    "            Ilp = TLps[0]\n",
    "            Ilp = cv2.cvtColor(Ilp, cv2.COLOR_BGR2GRAY)\n",
    "            Ilp = cv2.cvtColor(Ilp, cv2.COLOR_GRAY2BGR)\n",
    "            cv2.imwrite('./temp/lp'+str(i)+'.jpg',255*Ilp)\n",
    "            ocr_text = get_ocr(i)\n",
    "            recovered_characters.append(len([t for t in \"BGJ6974\" if t in ocr_text]))\n",
    "    del gy\n",
    "    del Yr\n",
    "    torch.cuda.empty_cache()\n",
    "#image = gy[0].repeat(1,1,912).cpu().detach().numpy().transpose(1, 2, 0)\n",
    "#print(max_accuracies)\n",
    "plt.plot(max_accuracies)\n",
    "plt.show()\n",
    "plt.plot(recovered_characters)\n",
    "plt.show()\n",
    "'''\n",
    "image = (gy[0]*Tn)[0].cpu().detach().numpy().transpose(1, 2, 0)\n",
    "print(image.shape)\n",
    "b = image.copy()\n",
    "b[:,:,1] = 0\n",
    "b[:,:,2] = 0\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
