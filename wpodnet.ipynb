{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_model import load_wpod\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms, utils, models\n",
    "from torch import nn\n",
    "import torch\n",
    "from src.label import Label, Shape\n",
    "from src.utils import getWH, nms, im2single, IOU_centre_and_dims\n",
    "from src.projection_utils import getRectPts, find_T_matrix\n",
    "import time\n",
    "from utils import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_to_tensor = transforms.ToTensor()\n",
    "tensor_to_pil = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLabel (Label):\n",
    "\n",
    "    def __init__(self,cl,pts,prob):\n",
    "        self.pts = pts\n",
    "        tl = np.amin(pts,1)\n",
    "        br = np.amax(pts,1)\n",
    "        Label.__init__(self,cl,tl,br,prob)\n",
    "\n",
    "\n",
    "def reconstruct(Iorig,I,Y,out_size,threshold=.9):\n",
    "\n",
    "    net_stride \t= 2**4\n",
    "    side = ((208. + 40.)/2.)/net_stride # 7.75\n",
    "    \n",
    "    Probs = Y[...,0]\n",
    "    Affines = Y[...,2:]\n",
    "    rx,ry = Y.shape[:2]\n",
    "    ywh = Y.shape[1::-1]\n",
    "    iwh = np.array(I.shape[1::-1],dtype=float).reshape((2,1))\n",
    "    xx,yy = np.where(Probs>threshold)\n",
    "    \n",
    "    WH = getWH(I.shape)\n",
    "    MN = WH/net_stride\n",
    "\n",
    "    vxx = vyy = 0.5 #alpha\n",
    "\n",
    "    base = lambda vx,vy: np.matrix([[-vx,-vy,1.],[vx,-vy,1.],[vx,vy,1.],[-vx,vy,1.]]).T\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(xx)):\n",
    "        y,x = xx[i],yy[i]\n",
    "        affine = Affines[y,x]\n",
    "        prob = Probs[y,x]\n",
    "        mn = np.array([float(x) + .5,float(y) + .5])\n",
    "        A = np.reshape(affine,(2,3))\n",
    "        A[0,0] = max(A[0,0],0.)\n",
    "        A[1,1] = max(A[1,1],0.)\n",
    "        pts = np.array(A*base(vxx,vyy)) #*alpha\n",
    "        pts_MN_center_mn = pts*side\n",
    "        pts_MN = pts_MN_center_mn + mn.reshape((2,1))\n",
    "\n",
    "        pts_prop = pts_MN/MN.reshape((2,1))\n",
    "\n",
    "        labels.append(DLabel(0,pts_prop,prob))\n",
    "\n",
    "    final_labels = nms(labels,.1)\n",
    "    TLps = []\n",
    "\n",
    "    if len(final_labels):\n",
    "        final_labels.sort(key=lambda x: x.prob(), reverse=True)\n",
    "        for i,label in enumerate(final_labels):\n",
    "\n",
    "            t_ptsh \t= getRectPts(0,0,out_size[0],out_size[1])\n",
    "            ptsh \t= np.concatenate((label.pts*getWH(Iorig.shape).reshape((2,1)),np.ones((1,4))))\n",
    "            H \t\t= find_T_matrix(ptsh,t_ptsh)\n",
    "            Ilp \t= cv2.warpPerspective(Iorig,H,out_size,borderValue=.0)\n",
    "\n",
    "            TLps.append(Ilp)\n",
    "\n",
    "    return final_labels,TLps\n",
    "    \n",
    "\n",
    "def detect_lp(model,I,max_dim,net_step,out_size,threshold,masked_pattern=None,train=None):\n",
    "\n",
    "    min_dim_img = min(I.shape[:2])\n",
    "    factor \t\t= float(max_dim)/min_dim_img\n",
    "\n",
    "    w,h = (np.array(I.shape[1::-1],dtype=float)*factor).astype(int).tolist()\n",
    "    w += (w%net_step!=0)*(net_step - w%net_step)\n",
    "    h += (h%net_step!=0)*(net_step - h%net_step)\n",
    "    Iresized = cv2.resize(I,(w,h))\n",
    "\n",
    "    Tn = Iresized.copy()\n",
    "    Tn = Tn.reshape((1,Tn.shape[0],Tn.shape[1],Tn.shape[2]))\n",
    "    Tn = torch.tensor(Tn, device=device).permute(0,3,1,2)\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    if masked_pattern is not None:\n",
    "        Tn = masked_pattern*Tn[0]\n",
    "    if train:\n",
    "        Yr = model(Tn).permute(0,2,3,1)\n",
    "        Yr = np.squeeze(Yr)\n",
    "        return None,None,None,Yr,Tn\n",
    "    else:\n",
    "        Yr = model(Tn).permute(0,2,3,1)\n",
    "        Yr = np.squeeze(Yr)\n",
    "        Y2 = Yr.cpu().detach().numpy()\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    L,TLps = reconstruct(I,Iresized,Y2,out_size,threshold)\n",
    "\n",
    "    return L,TLps,elapsed,Yr.cpu(),Tn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels2output_map(label,lppts,dim,stride):\n",
    "\n",
    "\tside = ((float(dim) + 40.)/2.)/stride # 7.75 when dim = 208 and stride = 16\n",
    "\n",
    "\toutsize = int(dim/stride)\n",
    "\tY  = np.zeros((outsize,outsize,2*4+1),dtype='float32')\n",
    "\tMN = np.array([outsize,outsize])\n",
    "\tWH = np.array([dim,dim],dtype=float)\n",
    "\n",
    "\ttlx,tly = np.floor(np.maximum(label.tl(),0.)*MN).astype(int).tolist()\n",
    "\tbrx,bry = np.ceil (np.minimum(label.br(),1.)*MN).astype(int).tolist()\n",
    "\n",
    "\tfor x in range(tlx,brx):\n",
    "\t\tfor y in range(tly,bry):\n",
    "\n",
    "\t\t\tmn = np.array([float(x) + .5, float(y) + .5])\n",
    "\t\t\tiou = IOU_centre_and_dims(mn/MN,label.wh(),label.cc(),label.wh())\n",
    "\n",
    "\t\t\tif iou > .5:\n",
    "\n",
    "\t\t\t\tp_WH = lppts*WH.reshape((2,1))\n",
    "\t\t\t\tp_MN = p_WH/stride\n",
    "\n",
    "\t\t\t\tp_MN_center_mn = p_MN - mn.reshape((2,1))\n",
    "\n",
    "\t\t\t\tp_side = p_MN_center_mn/side\n",
    "\n",
    "\t\t\t\tY[y,x,0] = 1.\n",
    "\t\t\t\tY[y,x,1:] = p_side.T.flatten()\n",
    "\n",
    "\treturn Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_pts(pts,lroi):\n",
    "\treturn pts*lroi.wh().reshape((2,1)) + lroi.tl().reshape((2,1))\n",
    "\n",
    "\n",
    "output_dir = \"./temp\"\n",
    "\n",
    "lp_threshold = .5\n",
    "\n",
    "wpod_net = load_wpod()\n",
    "wpod_net.to(device)\n",
    "wpod_net.eval()\n",
    "print('Searching for license plates using WPOD-NET')\n",
    "\n",
    "Ivehicle = cv2.imread('Plate_examples/lptest.jpg')\n",
    "#Ivehicle = cv2.resize(Ivehicle,(208,208))\n",
    "#Ivehicle = Ivehicle[450:630, 480:1170]\n",
    "plt.imshow(Ivehicle)\n",
    "print(Ivehicle.shape)\n",
    "#Ivehicle = cv2.bitwise_and(Ivehicle, Ivehicle, mask=cv2.bitwise_not(get_mask(Ivehicle)))\n",
    "ratio = float(max(Ivehicle.shape[:2]))/min(Ivehicle.shape[:2])\n",
    "side  = int(ratio*288.)\n",
    "bound_dim = min(side + (side%(2**4)),608)\n",
    "print(\"\\t\\tBound dim: %d, ratio: %f\" % (bound_dim,ratio)) \n",
    "\n",
    "Llp,LlpImgs,_,Y,_ = detect_lp(wpod_net,im2single(Ivehicle),bound_dim,2**4,(240,80),lp_threshold)\n",
    "\n",
    "if len(LlpImgs):\n",
    "    print('found')\n",
    "    Ilp = LlpImgs[0]\n",
    "    Ilp = cv2.cvtColor(Ilp, cv2.COLOR_BGR2GRAY)\n",
    "    Ilp = cv2.cvtColor(Ilp, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    s = Shape(Llp[0].pts)\n",
    "\n",
    "    plt.imshow(Ilp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl,br = s.pts.min(1),s.pts.max(1)\n",
    "llp = Label(0,tl,br)\n",
    "Y = labels2output_map(llp,s.pts,288,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[...,0][np.where(Y[...,0]>0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(Ivehicle,h=None,w=None,d=None):\n",
    "    if h:\n",
    "        height,width,depth = h,w,d\n",
    "    else: height,width,depth = Ivehicle.shape\n",
    "    x = Ivehicle.copy()\n",
    "    x = cv2.resize(x,(height,width))\n",
    "    circle_img = np.zeros((height,width), np.uint8)\n",
    "    #cv2.rectangle(circle_img,(86,107),(212,152),280,thickness=-1)\n",
    "    #cv2.rectangle(circle_img,(86,107),(212,152),280,thickness=-1)\n",
    "    print(circle_img.shape)\n",
    "    #circle_img = circle_img.reshape((1,circle_img.shape[0],circle_img.shape[1]))\n",
    "    #circle_img = torch.tensor(circle_img).permute(0,1,2)\n",
    "    #cv2.rectangle(circle_img,(480,480),(1170,570),255,thickness=-1)\n",
    "    plt.imshow(cv2.bitwise_and(x, x, mask=circle_img))\n",
    "    return circle_img\n",
    "get_mask(Ivehicle,288,288,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_resize = True\n",
    "repeat_size=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For resize post convolution\n",
    "if account_resize:\n",
    "    repeat_size = int(3024/3024)\n",
    "    img = Ivehicle.resize((208,208))\n",
    "    model_img_size = img.size[0]\n",
    "    img_t = pil_to_tensor(img)\n",
    "    img_t = img_t.to(device)\n",
    "    def resize2d(img, size):\n",
    "        return (F.adaptive_avg_pool2d(Variable(img), size)).data\n",
    "    def upsample2d(img, size=224):\n",
    "        upsample = nn.Upsample(size=size, mode='bilinear', align_corners=False)\n",
    "        return upsample(torch.unsqueeze(img, 0))[0]\n",
    "else:\n",
    "    model_img_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_img_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical exposure is in form 1/n s. Available: 15, 20, 25 30, 40, 50, 60, 80, 100, 125, 160, 200, 250\n",
    "exposure = 125 \n",
    "exp_micros = 1000000/exposure          # get exposure in microseconds\n",
    "img_ratio = 2 / model_img_size      # every row in model is img_ratio rows in original image\n",
    "model_tr = 10 * img_ratio              # multiply real tr (10 micros) by img_ratio to find model tr\n",
    "conv_size = exp_micros / model_tr      # divide exposure time by tr to find convolution size\n",
    "conv_size = int(conv_size)             # Need closest integer approximation. Won't cause a significant difference\n",
    "conv_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ivehicle = cv2.imread('Plate_examples/lptest.jpg')\n",
    "r = cv2.imread('Plate_examples/lp_red.jpg')\n",
    "r = cv2.cvtColor(r, cv2.COLOR_BGR2RGB)\n",
    "g = cv2.imread('Plate_examples/lp_green.jpg')\n",
    "b = cv2.imread('Plate_examples/lp_blue.jpg')\n",
    "b = cv2.cvtColor(r, cv2.COLOR_BGR2RGB)\n",
    "w = cv2.imread('Plate_examples/lp_white.jpg')\n",
    "canvas = np.zeros([2268,4032,3],dtype=np.uint8)\n",
    "canvas[:,:,0] = r[:,:,0]\n",
    "canvas[:,:,1] = g[:,:,1]\n",
    "canvas[:,:,2] = b[:,:,2]\n",
    "Ivehicle = canvas\n",
    "Ivehicle.shape\n",
    "#Ivehicle = cv2.cvtColor(Ivehicle, cv2.COLOR_BGR2RGB)\n",
    "#Ivehicle = cv2.resize(Ivehicle,(208,208))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = model_img_size + conv_size - 1 # 300   #Length of input signal\n",
    "c = 0    #Ambient light ratio\n",
    "c_limits = [0,0]\n",
    "batch = 8\n",
    "channels = 3\n",
    "# change of variable term to optimise on\n",
    "w = torch.rand([channels,sz,1], requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "#Create the mask to only illuminate the object\n",
    "#mask = torch.tensor(get_mask(Ivehicle,288,288,3), dtype=torch.float, device=device)\n",
    "#mask = torch.tensor(get_mask(Ivehicle,288,288,3), device=device)\n",
    "mask = torch.ones([3,512,912], device=device)\n",
    "mask = mask / torch.max(mask)\n",
    "#mask = get_mask(Ivehicle,288,288,3)\n",
    "\n",
    "#Target and original class labels\n",
    "#orig = torch.tensor([classidx], dtype=torch.long, device=device)\n",
    "\n",
    "#Model parameters\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "optimizer = optim.SGD([w], lr=lr, momentum=0.9, nesterov=True)\n",
    "#optimizer = optim.Adam([w], lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelf = torch.flatten(torch.tensor(Y[...,0], dtype=torch.float, device=device))\n",
    "labelnf = torch.flatten(torch.tensor(1-Y[...,0], dtype=torch.float, device=device))\n",
    "def logloss(ptrue, pred, eps=10e-10):\n",
    "    Pred = torch.clamp(pred,eps,1.)\n",
    "    Pred = -torch.log(Pred)\n",
    "    Pred = torch.dot(Pred,ptrue)\n",
    "    #Pred = torch.reshape(Pred,(b,h*w*ch))\n",
    "    #Pred = torch.sum(Pred,1)\n",
    "    return Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_run(update_frequency, print_frequency, n_epochs):\n",
    "    #Track the loss to target and original class\n",
    "    loss_list = []\n",
    "\n",
    "    #obj_dict = {}\n",
    "    #w = -1*w\n",
    "    #Optimisation loop. initially untargeted\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "\n",
    "        if channels==1:\n",
    "            n_w = w.repeat(3,1,1)\n",
    "        else:\n",
    "            n_w = w\n",
    "        #with torch.no_grad():\n",
    "        #    n_w = torch.clamp(n_w, max=1)\n",
    "        # For resize post convolution\n",
    "        #if account_resize:\n",
    "        #    n_w = torch.repeat_interleave(n_w, repeats=repeat_size, dim=1)\n",
    "\n",
    "        sig_height = model_img_size + conv_size - 1\n",
    "        gy, new_w = fttogy(n_w, batch, None, c_limits, sig_height, conv_size, 0)\n",
    "        #pattern = 1-mask + torch.mul(gy,mask)\n",
    "        #new_w.retain_grad()\n",
    "        #gy.retain_grad()\n",
    "        #with torch.autograd.set_detect_anomaly(True):\n",
    "        Llp,LlpImgs,x,Yr,T = detect_lp(wpod_net,im2single(Ivehicle),bound_dim,2**4,(240,80),lp_threshold,gy,train=True)\n",
    "        #Yr.retain_grad()\n",
    "        #loss = -1*torch.sum(torch.log(1-Yr[...,0][np.where(Y[...,0]>0.5)]))\n",
    "        loss = -1*torch.log(1-torch.max(torch.max(Yr[...,0],dim=1)[0],dim=1)[0])\n",
    "        loss = torch.sum(loss)\n",
    "        #loss.retain_grad()\n",
    "        if epoch%print_frequency==0:\n",
    "            #print(Yr[...,0][np.where(Y[...,0]>0.5)])\n",
    "            loss_list.append(loss)\n",
    "\n",
    "        if epoch%100==0:\n",
    "            #print(Yr[...,0][np.where(Y[...,0]>0.5)])\n",
    "            print(loss)\n",
    "            \n",
    "        loss.backward()   \n",
    "\n",
    "        if epoch%update_frequency==0:\n",
    "            #print('loss_grad',loss.grad)\n",
    "            #print('gy_grad', gy.grad[gy.grad>0])\n",
    "            #print('w_grad', w.grad)\n",
    "            #print('new_w', new_w.grad[new_w.grad>0])\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            del loss\n",
    "            torch.cuda.empty_cache()\n",
    "        #if epoch!=n_epochs-1:\n",
    "        #    del inp\n",
    "        #    del new_w\n",
    "        #else:\n",
    "            #saving w to be used for prediction\n",
    "            #torch.save(n_w,'w_0.5_764.pt')\n",
    "\n",
    "        #Code to check gpu allocation    \n",
    "        '''\n",
    "        for obj in gc.get_objects():\n",
    "            try:\n",
    "                if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "                    #print(type(obj), obj.size())\n",
    "                    if type(obj) not in obj_dict:\n",
    "                        obj_dict[type(obj)] = 1\n",
    "                    else:\n",
    "                        obj_dict[type(obj)] += 1\n",
    "            except: pass\n",
    "        print(obj_dict)\n",
    "        obj_dict.clear()\n",
    "        '''\n",
    "    return loss_list, Yr, gy, new_w, T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View original loss and target loss\n",
    "update_freqs = [20]\n",
    "result = []\n",
    "for up in update_freqs:\n",
    "    #w = torch.rand([channels,sz,1], requires_grad=True, dtype=torch.float, device=device)\n",
    "    optimizer = optim.SGD([w], lr=1, momentum=0.9, nesterov=True)\n",
    "    #optimizer = optim.Adam([w], lr=20)\n",
    "    result.append(train_run(up, 10, 1000))\n",
    "    plt.plot([x.item() for x in result[-1][0]], label=str(up))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_to_pil(result[0][4][7].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(batch):\n",
    "    print(i)\n",
    "    print(torch.mean(result[0][1][i][:,:,0][np.where(Y[:,:,0]>0.5)]).item())\n",
    "    print(result[0][1][i][:,:,0][result[0][1][i][:,:,0]>0.5].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tensor_to_pil(result[0][2][0].repeat(1,1,912).cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.flatten(result[0][3][0][0]).detach().cpu(), label=\"w_r\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(torch.flatten(result[0][3][0][1]).detach().cpu(), label=\"w_g\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(torch.flatten(result[0][3][0][2]).detach().cpu(), label=\"w_b\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Llp,LlpImgs,_,Y2,_ = detect_lp(wpod_net,im2single(Ivehicle),bound_dim,2**4,(240,80),lp_threshold,result[0][2][7:8])\n",
    "\n",
    "if len(LlpImgs):\n",
    "    print('found')\n",
    "    Ilp = LlpImgs[0]\n",
    "    Ilp = cv2.cvtColor(Ilp, cv2.COLOR_BGR2GRAY)\n",
    "    Ilp = cv2.cvtColor(Ilp, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    s = Shape(Llp[0].pts)\n",
    "\n",
    "    plt.imshow(Ilp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[...,0][np.where(Y[...,0]>0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
