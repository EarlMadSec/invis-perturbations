{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from GTSRBNet import GTSRBNet\n",
    "from GTSRBDataset import GTSRBDataset\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ''\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0))])\n",
    "\n",
    "validset = GTSRBDataset('valid_us.npz', transform=transform)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = GTSRBNet()\n",
    "model.to(device)\n",
    "\n",
    "classes = []\n",
    "with open(root + 'class_semantics.txt') as f:\n",
    "    for line in f:\n",
    "        classes.append(line.strip())\n",
    "\n",
    "checkpoint = torch.load('checkpoint_us.tar',map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def imshow(img):\n",
    "    img = img + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "def saveim(img, name):\n",
    "    save_image(img, name)\n",
    "def readim(name):\n",
    "    image = Image.open(name)\n",
    "    x = TF.to_tensor(image)\n",
    "    tform = transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0))\n",
    "    x = tform(x)\n",
    "    x.unsqueeze_(0)\n",
    "    return x\n",
    "def stack(w,size):\n",
    "    dim = len(torch.flatten(w))\n",
    "    if dim == size:\n",
    "        return w\n",
    "    ide = torch.eye(dim, requires_grad=True, dtype=torch.float, device=device)\n",
    "    zer = torch.zeros([1,dim], requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "    n = size // dim\n",
    "    m = size % dim\n",
    "    nsum = torch.zeros([1,1,size,1], requires_grad=True, dtype=torch.float, device=device)\n",
    "    ides = torch.cat(n*[ide])\n",
    "    if m != 0:\n",
    "        zers = torch.cat(m*[zer])\n",
    "        mat = torch.cat([ides,zers])\n",
    "    else:\n",
    "        mat = ides\n",
    "    nsum = nsum + torch.matmul(mat,w)\n",
    "    if m == 0:\n",
    "        return nsum\n",
    "    t = []\n",
    "    for i in range(m):\n",
    "        t.append(torch.tensor([1 if x == i else 0 for x in range(dim)],requires_grad=True, dtype=torch.float, device=device))\n",
    "\n",
    "    mat2 = torch.cat([torch.cat(dim*n*[zer]),torch.stack(t)])\n",
    "    nsum = nsum + torch.matmul(mat2,w)\n",
    "    return nsum\n",
    "def gamma_correction(img, factor):\n",
    "    return ((img+0.5)**factor)-0.5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Old getting random initial image\n",
    "ite = next(iter(validloader)) #batch of 256\n",
    "classidx = ite[1][0]\n",
    "o_class = classes[classidx]\n",
    "print(o_class)\n",
    "print(classidx)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input_ime = ite[0][0].cuda()\n",
    "input_im = input_ime.unsqueeze(0)\n",
    "imshow(input_ime.cpu())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input_im = ite[0][ite[1] == 14][2].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classidx = 14 #or 34 for left turn\n",
    "targidx = 13 #yield\n",
    "o_class = classes[classidx]\n",
    "print(o_class)\n",
    "print(classidx)\n",
    "cls = 'stop' #change to lturn for left turn\n",
    "\n",
    "input_im = readim(\"images/original/{}.png\".format(cls))\n",
    "xadv = readim(\"images/adversarial/{}adv36.png\".format(cls))\n",
    "input_im = input_im.to(device)\n",
    "xadv = xadv.to(device)\n",
    "out = model(input_im)\n",
    "outadv = model(xadv)\n",
    "imshow(input_im[0].cpu())\n",
    "imshow(xadv[0].cpu())\n",
    "\n",
    "lay2 = torch.nn.Softmax(dim=1)\n",
    "prob = lay2(out)\n",
    "prob2 = lay2(outadv)\n",
    "print(prob.max(1), prob2.max(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_mask(input_image):\n",
    "    test = np.uint8((input_image+0.5).numpy()*255).transpose((1,2,0))\n",
    "    test[0][:] = test[1][:]\n",
    "    test[-1][:] = test[-3][:]\n",
    "    test[-2][:] = test[-3][:]\n",
    "    #print(test[-3][:])\n",
    "    gray = cv2.cvtColor(test, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(test, (3, 3), 0)\n",
    "    edged = cv2.Canny(blurred, 0, 255)   \n",
    "    #imgplot = plt.imshow(test)\n",
    "    #plt.show()\n",
    "    #imshow(input_image[0])\n",
    "    #applying closing function\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(9,9))\n",
    "    closed = cv2.morphologyEx(edged, cv2.MORPH_CLOSE, kernel)    #finding_contours\n",
    "    (cnts, _) = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)    \n",
    "    for c in cnts:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        cv2.drawContours(closed, [approx], -1, (0, 255, 0), 2)    \n",
    "    th, im_th = cv2.threshold(closed, 220, 255, cv2.THRESH_BINARY_INV);    \n",
    "    h, w = im_th.shape[:2]\n",
    "    im_floodfill = im_th.copy()\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "    cv2.floodFill(im_floodfill, mask, (0,0), 0);    # Invert floodfilled image\n",
    "    im_floodfill_inv = cv2.bitwise_not(im_floodfill)    # Combine the two images to get the foreground.\n",
    "    im_out = im_th ^ im_floodfill_inv\n",
    "    return im_out\n",
    "imshow(input_im[0].cpu())\n",
    "imgplot = plt.imshow(get_object_mask(input_im[0].cpu()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input time signal\n",
    "sz = 36\n",
    "w = torch.rand([1,1,sz,1], requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "#Does not work since no useful gradients\n",
    "#Aw = torch.rand([1], requires_grad=True, dtype=torch.float, device=device) #amplitude and frequency\n",
    "#sample = torch.linspace(0, 4, sz, dtype=torch.float, device=device)  #Sampling rate, do the math to get this\n",
    "#w = torch.sin(100*Aw[0]*sample).view([1,1,sz,1]) #Sample the sine wave\n",
    "\n",
    "mask = torch.tensor(get_object_mask(input_im[0].cpu()))\n",
    "mask = mask / torch.max(mask)\n",
    "mask = mask.to(device)\n",
    "#The shutter function is encoded into the convolution layer\n",
    "lay = torch.nn.Conv1d(1,1,5)\n",
    "lay.to(device)\n",
    "\n",
    "#Manually setting the weights and bias so the  shutter acts as a box filter\n",
    "lay.weight.data = torch.full([1,1,5,1], .2, requires_grad=True, dtype=torch.float, device=device)\n",
    "lay.bias.data = torch.zeros(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "#Target and original class labels\n",
    "target = torch.tensor([targidx], dtype=torch.long, device=device) #Yield\n",
    "orig = torch.tensor([classidx], dtype=torch.long, device=device)\n",
    "\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "optimizer = optim.SGD([w], lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targloss = []\n",
    "origloss = []\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # Compute g(y) to get X_adv\n",
    "    #gy = lay(ft)    \n",
    "    #w = torch.tanh(gy)\n",
    "    \n",
    "    oot = stack(w,36)\n",
    "    new_w = .5 * (torch.tanh(oot) + 1)\n",
    "    #new_w = .5 * (oot + 1) #Method using Sin, does not work, no gradients\n",
    "    gy = lay(new_w)             #Convolution of ft and the shutter\n",
    "    gy_mask = gy * mask\n",
    "    #gy_mask = gy_mask + (1 - mask)\n",
    "    inp = (input_im + .5) + (gamma_correction(input_im[0], 0.4) - input_im)*(gy_mask) - 0.5         #gy is broadcasted to match the shape of input_im\n",
    "    out = model(inp)\n",
    "    \n",
    "    #Calculate Loss\n",
    "    loss = loss_fn(out, target)\n",
    "    targloss.append(loss.data)\n",
    "    origloss.append(loss_fn(out,orig))\n",
    "    loss.backward(retain_graph=True)\n",
    "    \n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "plt.plot(targloss, label=\"target\")\n",
    "plt.plot(origloss, label=\"original\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(targloss[25:], label=\"target\")\n",
    "plt.plot(origloss[25:], label=\"original\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lay2 = torch.nn.Softmax(dim=1)\n",
    "prob = lay2(out)\n",
    "#prob2 = lay2(out2)\n",
    "prob.max(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.ones([1,3,32,32], device=device)\n",
    "test = test * (gy)\n",
    "imshow(test[0].detach().cpu() - .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.flatten(w).detach().cpu(), label=\"w\")\n",
    "plt.plot(torch.flatten(new_w).detach().cpu(), label=\"new_w\")\n",
    "plt.plot(torch.flatten(gy).detach().cpu(),label=\"gy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(torch.flatten(new_w).detach().cpu(), label=\"new_w\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.ones([1,3,32,32], device=device)\n",
    "test = test * (gy_mask )\n",
    "imshow(test[0].detach().cpu() - .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(inp[0].detach().cpu())\n",
    "saveim(inp[0].detach().cpu() + 0.5, \"images/adversarial/{}adv{}.png\".format(cls,sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(((input_im[0].cpu()+.5) ) - 0.5)\n",
    "imshow(gamma_correction(input_im[0].cpu(), 0.4))\n",
    "saveim(input_im + 0.5, \"images/original/{}.png\".format(cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "conf = []\n",
    "true = []\n",
    "lay2 = torch.nn.Softmax(dim=1)\n",
    "input_im = readim(\"images/original/{}.png\".format(cls))\n",
    "input_im = input_im.to(device)\n",
    "out = model(input_im)\n",
    "trueprob = lay2(out)\n",
    "imshow(input_im[0].cpu())\n",
    "\n",
    "img_path = \"images/adversarial/\"\n",
    "file_names = [fn for fn in os.listdir(img_path) if fn[:len(cls)] == cls]\n",
    "for i in file_names:\n",
    "    l.append(int(i[len(cls)+3:-4]))\n",
    "    xadv = readim(\"images/adversarial/{}\".format(i)).to(device)\n",
    "    out = model(xadv)\n",
    "    imshow(xadv[0].cpu())\n",
    "    prob = lay2(out)\n",
    "    conf.append(prob[0][target[0].item()])\n",
    "    true.append(prob[0][classidx])\n",
    "plt.plot(l,conf,\"ro\", label=\"Target\")\n",
    "plt.plot(l,true, \"go\", label=\"True\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(conf,true, \"ro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
