{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from GTSRBNet import GTSRBNet\n",
    "from GTSRBDataset import GTSRBDataset\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ''\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0))])\n",
    "\n",
    "validset = GTSRBDataset('valid_us.npz', transform=transform)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = GTSRBNet()\n",
    "model.to(device)\n",
    "\n",
    "classes = []\n",
    "with open(root + 'class_semantics.txt') as f:\n",
    "    for line in f:\n",
    "        classes.append(line.strip())\n",
    "\n",
    "checkpoint = torch.load('checkpoint_us.tar')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ite = next(iter(validloader)) #batch of 256\n",
    "classidx = ite[1][0]\n",
    "o_class = classes[classidx]\n",
    "print(o_class)\n",
    "print(classidx)\n",
    "classes[16]\n",
    "input_ime = ite[0][0].cuda()\n",
    "input_im = input_ime.unsqueeze(0)\n",
    "imshow(input_ime.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Bound the ft/gy so that the image is a valid rgb image.\n",
    "#TODO: See if Conv1d is an accurate representation of the convolution\n",
    "\n",
    "# The input time signal\n",
    "ft = torch.ones([1,1,36,1], requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "#The shutter function is encoded into the convolution layer\n",
    "lay = torch.nn.Conv1d(1,1,5)\n",
    "lay.to(device)\n",
    "\n",
    "#Manually setting the weights and bias so the  shutter acts as a box filter\n",
    "lay.weight.data = torch.ones([1,1,5,1], requires_grad=True, dtype=torch.float, device=device)\n",
    "lay.bias.data = torch.zeros(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "#Target and original class labels\n",
    "target = torch.tensor([16], dtype=torch.long, device=device)\n",
    "orig = torch.tensor([classidx], dtype=torch.long, device=device)\n",
    "targloss = []\n",
    "origloss = []\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "optimizer = optim.SGD([ft], lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # Compute g(y) to get X_adv\n",
    "    gy = lay(ft)    #Convolution of ft and the shutter\n",
    "    inp = input_im * gy           #gy is broadcasted to match the shape of input_im\n",
    "    out = model(inp)\n",
    "    \n",
    "    #Calculate Loss\n",
    "    loss = loss_fn(out, target)\n",
    "    targloss.append(loss.data)\n",
    "    origloss.append(loss_fn(out,orig))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "plt.plot(targloss, label=\"target\")\n",
    "plt.plot(origloss, label=\"original\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(targloss[100:], label=\"target\")\n",
    "plt.plot(origloss[100:], label=\"original\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2 = (input_ime - torch.min(input_ime))\n",
    "inp2 /= torch.max(inp2)\n",
    "imshow(inp2.cpu())\n",
    "imshow(input_ime.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2 = (inp - torch.min(inp))\n",
    "inp2 /= torch.max(inp2)\n",
    "imshow(inp2[0].detach().cpu())\n",
    "imshow(inp[0].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.ones([1,3,32,32], device=device)\n",
    "test2 = gy - torch.min(gy)\n",
    "test2 /= torch.max(test2)\n",
    "test = test * test2\n",
    "imshow(test[0].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.flatten(ft).detach().cpu())\n",
    "plt.plot(torch.flatten(gy).detach().cpu())\n",
    "plt.show()\n",
    "plt.plot(torch.flatten(test2).detach().cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.min(input_im),torch.max(input_im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
